{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project for IBM Data Science Program\n",
    "\n",
    "## My project: Find My Home \n",
    "\n",
    "\n",
    "### Introduction Section\n",
    "\n",
    "For my capstone project, I will be looking at the city of Sydney, Australia. The user that I have in mind is someone that is looking to decide on a neighborhood to move to. My goal is to be able to find the neighborhoods that best match the user. To accomplish this, I will be developing profiles for each neighborhood and matching it to the user's lifestyle preferences (selected via their top 5 important venue catgories to them). \n",
    "\n",
    "### Data Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was done in the previous modules, a data table with the coordinates and names of neighborhoods in Sydney is needed. I will start with an HTML table that is accessible via a search for this information. Then, we will use Foursquare data to get venue data for each area. This will be enough to develop a clustering of similar areas. \n",
    "\n",
    "A content-based recommendation system will then be developed using venue categories as the features of the neighborhood. No additional data will be needed. I will use a fake user profile to showcase the system's output given their top 5 venue categories. Below is my first step of getting the location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs:\n",
      "    - geopy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2020.12.5          |   py36h5fab9bb_1         143 KB  conda-forge\n",
      "    geographiclib-1.50         |             py_0          34 KB  conda-forge\n",
      "    geopy-2.1.0                |     pyhd3deb0d_0          64 KB  conda-forge\n",
      "    openssl-1.1.1j             |       h7f98852_0         2.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  geographiclib      conda-forge/noarch::geographiclib-1.50-py_0\n",
      "  geopy              conda-forge/noarch::geopy-2.1.0-pyhd3deb0d_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                          2020.12.5-py36h5fab9bb_0 --> 2020.12.5-py36h5fab9bb_1\n",
      "  openssl                                 1.1.1i-h7f98852_0 --> 1.1.1j-h7f98852_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "geopy-2.1.0          | 64 KB     | ##################################### | 100% \n",
      "openssl-1.1.1j       | 2.1 MB    | ##################################### | 100% \n",
      "certifi-2020.12.5    | 143 KB    | ##################################### | 100% \n",
      "geographiclib-1.50   | 34 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json \n",
    "\n",
    "!conda install -c conda-forge geopy --yes \n",
    "from geopy.geocoders import Nominatim \n",
    "\n",
    "import requests \n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs:\n",
      "    - beautifulsoup4\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    beautifulsoup4-4.9.3       |     pyhb0f4dca_0          86 KB  conda-forge\n",
      "    soupsieve-2.0.1            |             py_1          30 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         116 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.9.3-pyhb0f4dca_0\n",
      "  soupsieve          conda-forge/noarch::soupsieve-2.0.1-py_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "beautifulsoup4-4.9.3 | 86 KB     | ##################################### | 100% \n",
      "soupsieve-2.0.1      | 30 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge beautifulsoup4 --y\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are ready to go for the table from the HTML page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = requests.get('https://www.geonames.org/postal-codes/AU/NSW/new-south-wales.html')\n",
    "geo.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(geo.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table',class_='restable') #The Source Code in the HTML points to this as the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are taking each row's data elements (td) and stripping it of the text. \n",
    "table_rows = table.find_all('td')\n",
    "\n",
    "def slice_per(source, step):\n",
    "    return [source[i::step] for i in range(step)]\n",
    "\n",
    "data = slice_per(table_rows,9) #Due to complexity of table structure, this function will separate out every 9th item for each soon-to-be column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTML list of td had a repetition of every 9 had all of the row information. (0 is #, 1 is Place, 2 is code, 3 is country, 4 is state, 5 is area, 6 is what broke the soup extraction, 7 nil, 8 is latlong.) \n",
    "\n",
    "Now, each list in the 'data' list needs to be formatted before being added to a column in a dataframe. We only need Place, Code, Area, and latlong. As part of this, the latlong list will need to be split into latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remove the items that we don't need\n",
    "del data[7]\n",
    "del data[6]\n",
    "del data[4]\n",
    "del data[3]\n",
    "del data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The main problem with most of them is the remaining HTML tags. Let's remove them.\n",
    "for sublist in data:\n",
    "    for i, s in enumerate(sublist):\n",
    "        sublist[i] = str(s).replace('<td>','').replace('</td>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Latlong item has a lot more in it than just td tags. We need a different approach to get to the coordinates only.\n",
    "import re\n",
    "\n",
    "for i in range(len(data[3])):\n",
    "    s = data[3][i]\n",
    "    result = re.search('<small>(.*)</small>', s)\n",
    "    data[3][i] = result.group(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Place':data[0],'Code':data[1],'Area':data[2],'Latlong':data[3]}) #Establish our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Latitude','Longitude']] = df['Latlong'].str.split('/',expand=True) #Split Latitude and Longitude into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Code</th>\n",
       "      <th>Area</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haymarket</td>\n",
       "      <td>2000</td>\n",
       "      <td>SYDNEY STREETS</td>\n",
       "      <td>-33.88</td>\n",
       "      <td>151.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ultimo</td>\n",
       "      <td>2007</td>\n",
       "      <td>SYDNEY STREETS</td>\n",
       "      <td>-33.881</td>\n",
       "      <td>151.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chippendale</td>\n",
       "      <td>2008</td>\n",
       "      <td>SYDNEY STREETS</td>\n",
       "      <td>-33.886</td>\n",
       "      <td>151.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pyrmont</td>\n",
       "      <td>2009</td>\n",
       "      <td>SYDNEY STREETS</td>\n",
       "      <td>-33.87</td>\n",
       "      <td>151.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surry Hills</td>\n",
       "      <td>2010</td>\n",
       "      <td>SYDNEY STREETS</td>\n",
       "      <td>-33.885</td>\n",
       "      <td>151.212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Place  Code            Area Latitude Longitude\n",
       "0    Haymarket  2000  SYDNEY STREETS   -33.88   151.205\n",
       "1       Ultimo  2007  SYDNEY STREETS  -33.881   151.198\n",
       "2  Chippendale  2008  SYDNEY STREETS  -33.886   151.199\n",
       "3      Pyrmont  2009  SYDNEY STREETS   -33.87   151.194\n",
       "4  Surry Hills  2010  SYDNEY STREETS  -33.885   151.212"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Latlong',axis=1,inplace=True) #Finally remove Latlong column\n",
    "df.head() #Complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
